# ğŸ¤– HUST Regulations Bot
<p align="center">
  [<a href="./docs/README-JP.md">ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª</a>]
</p>

[![Watch the video](./assets/DEMO.png)](https://www.youtube.com/watch?v=2S-cWeajxHs)
## Overview
To easily query the school's academic regulations (*Quy cháº¿ Ä‘Ã o táº¡o*) in natural language, this project aims to help students at **HUST (Hanoi University of Science and Technology)** by a **Retrieval-Augmented Generation (RAG) chatbot**.

The system uses a **Parent-Document-Retriever (PDR)** pattern with hybrid search (dense vector + BM25) and a router chain that automatically distinguishes between casual conversation and document-grounded Q&A.



## Prerequisites

| Requirement | Version / Notes |
|---|---|
| Python | `3.13+` (specific ver: `3.13.5`) |
| Groq API Key | Required - powers the LLM (`qwen/qwen3-32b`) |
| LangSmith API Key | Optional - for chain tracing |
| GPU (CUDA) | Optional - auto-detected (2GB VRAM minimum usage) ; CPU is the fallback for embeddings |

---

## Setup

### 1. Clone the repository
```bash
git clone https://github.com/mizuwonomu/rag-project.git
cd rag-project
```

### 2. Set up environment variables
Create a `.env` file in the project root:
```bash
GROQ_API_KEY=your_groq_api_key
LANGSMITH_API_KEY=your_langsmith_api_key   # Optional
```

### 3. Install dependencies
`uv` is preferred:
```bash
uv sync
# or with pip:
pip install -r requirements.txt
```

### 4. Build the vector store
* Create a `data_quyche/` folder inside project root.
* Place the source PDF [QCDT_2025_DHBK.pdf](https://ctt.hust.edu.vn/Upload/Nguy%E1%BB%85n%20Qu%E1%BB%91c%20%C4%90%E1%BA%A1t/files/DTDH_QDQC/Hoctap/QCDT_2025_5445_QD-DHBK.pdf) inside `data_quyche/`, then run:
```bash
python -m src.ingestion.ingest_regulations
```
This will:
- Split the PDF into *parent* chunks (one per "Äiá»u" article)
- Create *child* chunks (`chunk_size=400`, `chunk_overlap=50`) and embed them into ChromaDB (`chroma_db/` folder)
- Persist parent docs as **pickled bytes** in `doc_store_pdr/` (This will be generated automatically)

### 5. Run the app
```bash
streamlit run frontend/app.py
```

---

## How It Works

![image_alt](./assets/DIAGRAM.png)

```
User question
      â”‚
      â–¼
 Router chain â”€â”€â–º "chat"  â”€â”€â–º Friendly chat response 
                                  â”‚
                                  â–¼ 
                      Memory conversation + User Feedback
      â”‚
      â””â”€â”€â”€â”€â”€â”€â–º "RAG"
                  â”‚
                  â–¼
         EnsembleRetriever (child chunks only)
         â”œâ”€â”€ Dense: ChromaDB vector search  (weight 0.5)
         â””â”€â”€ Sparse: BM25 keyword search    (weight 0.5)
                  â”‚
                  â–¼
         Top-k child doc_ids â†’ fetch full parent docs from doc_store_pdr/
                  â”‚
                  â–¼
         QA chain (citation-enforced) â†’ streaming answer + sources
                  â”‚
                  â–¼
        Store into memory conversation + User feedback about response
```
## Project Structure

```
rag-project/
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                    # Streamlit frontend entry-point
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ qa_chain.py               # Core RAG/chat chain logic
â”‚   â”œâ”€â”€ utils.py                  # Shared utilities (embedding model loader)
â”‚   â””â”€â”€ ingestion/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ ingest_regulations.py # PDF ingestion & vector store population
â”œâ”€â”€ data_quyche/                  # Raw PDF documents (not versioned)
â”œâ”€â”€ chroma_db/                    # ChromaDB vector store (auto-generated, not versioned)
â”œâ”€â”€ doc_store_pdr/                # Parent doc store (auto-generated, not versioned)
â”œâ”€â”€ assets/                       # Static assets
â”œâ”€â”€ docs/                         # Additional documentation
â”œâ”€â”€ legacy/                       # Archived code â€” do not use
â”œâ”€â”€ feedback_log.csv              # User feedback log (auto-created, not versioned)
â”œâ”€â”€ .env                          # API keys â€” never commit
â”œâ”€â”€ pyproject.toml                # Project metadata & pinned dependencies
â”œâ”€â”€ requirements.txt              # pip install manifest
â””â”€â”€ uv.lock                       # uv lockfile â€” do not hand-edit
```

---

## Key Design Decisions

| Component | Choice | Reason |
|---|---|---|
| Embedding model | `BAAI/bge-m3` (HuggingFace) | Strong multilingual (Vietnamese) performance |
| Vector store | ChromaDB | Persistent, local, no server needed |
| Parent store | `LocalFileStore` + pickle | Preserves full article context per "Äiá»u" |
| Retrieval | EnsembleRetriever (dense + BM25) | Hybrid search balances semantic & keyword recall |
| LLM | `ChatGroq` - `qwen/qwen3-32b` | Fast inference via Groq API |
| Memory | In-process `ChatMessageHistory` | Lightweight single-session support |

---

## Notes

- `chroma_db/` and `doc_store_pdr/` are excluded from version control. Regenerate them with `python -m src.ingestion.ingest_regulations` after cloning.
- Never change the embedding model without re-running ingestion - the vector store and model must match.
- Keep `.env` file secure and never commit it.
